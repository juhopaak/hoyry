{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from libvoikko import Voikko\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voikko = Voikko(\"fi\")\n",
    "\n",
    "def clean(s):\n",
    "    s = re.sub(\"\\n\", \" \", s)\n",
    "    s = re.sub(\"  \", \" \", s)\n",
    "    s = s.strip()\n",
    "    return(s)\n",
    "\n",
    "def remove_punct(s):\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "    s = re.sub(\"§(\\S+)?\", \"\", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    s = re.sub(\"(^| ).( |$)\", \" \", s)\n",
    "    s = re.sub(\"–\", \"\", s)\n",
    "    s = re.sub('”', \"\", s)\n",
    "    s = s.strip()\n",
    "    s = s.lower()\n",
    "    return(s)\n",
    "\n",
    "def tokenize_sentences(text, voikko):\n",
    "    return [s.sentenceText.strip() for s in voikko.sentences(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINLEX-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/kho/\" + x for x in os.listdir(\"data/kho\")]\n",
    "paths += [\"data/kko/\" + x for x in os.listdir(\"data/kko\")]\n",
    "paths += [\"data/sd/\" + x for x in os.listdir(\"data/sd\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for p in paths:\n",
    "    with open(p, 'r') as f:\n",
    "        data += json.load(f)\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"year\", inplace = True)\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(\"index\", 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(df['text'])\n",
    "\n",
    "sentences = []\n",
    "for i in range(0, len(texts)):\n",
    "    tokens = tokenize_sentences( clean(texts[i]), voikko )\n",
    "    sentences += [remove_punct(t).split() for t in tokens]\n",
    "\n",
    "del texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2277594"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py\n",
    "model_ft = FastText(sentences, size = 200, window = 5, min_count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=211136, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.save(\"models/fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec(sentences, size = 200, window = 5, min_count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=211136, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.save(\"models/w2v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ennustetaan runoaineistolle lakimalliin pohjaavat uudet sanat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/cutups/\" + x for x in os.listdir(\"data/cutups\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for p in paths:\n",
    "    with open(p, \"r\") as f:\n",
    "        text = f.read()\n",
    "        text = clean(text)\n",
    "        text = remove_punct(text)\n",
    "        \n",
    "        data.append( text.split() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec.load(\"models/w2v\")\n",
    "model_ft = FastText.load(\"models/fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in total: 1627\n",
      "Words inferred with W2V model: 1056\n",
      "Words inferred with FT model: 571\n"
     ]
    }
   ],
   "source": [
    "pred = [ [] for i in range(12) ]\n",
    "\n",
    "words = 0\n",
    "w2v_pred = 0\n",
    "ft_pred = 0\n",
    "\n",
    "for runo_pos in range(len(data)):\n",
    "    \n",
    "    runo = data[runo_pos]\n",
    "    \n",
    "    for w_pos in range(len(runo)):\n",
    "        \n",
    "        words += 1\n",
    "        \n",
    "        # Yritetään päätellä uusi sana käyttäen w2v-mallia\n",
    "        try:\n",
    "            pred[runo_pos].append(model_w2v.wv.most_similar(runo[w_pos])[0])\n",
    "            w2v_pred += 1\n",
    "\n",
    "        # Jos sana ei ole sanastossa, käytetään FastText-mallin lähintä sanaa tai alkuperäistä sanaa\n",
    "        except:\n",
    "            #pred[runo_pos].append((runo[w_pos], 1))\n",
    "            pred[runo_pos].append(model_ft.wv.most_similar(runo[w_pos])[0])\n",
    "            ft_pred += 1\n",
    "\n",
    "print(\"Words in total: \"+ str(words))\n",
    "print(\"Words inferred with W2V model: \" + str(w2v_pred))\n",
    "print(\"Words inferred with FT model: \" + str(ft_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for p in reversed(pred):\n",
    "    \n",
    "    text = \"\"\n",
    "    prob = \"\"\n",
    "    \n",
    "    for word in p:\n",
    "        text += word[0] + \" \"\n",
    "        prob += str(word[1]) + \", \"\n",
    "    \n",
    "    with open(\"models/cutups/ft_\" + str(i) + \".txt\", \"w\") as f:\n",
    "        f.write(text + \" \" + prob)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
